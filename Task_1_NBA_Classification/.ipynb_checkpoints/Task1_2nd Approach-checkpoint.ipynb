{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "id": "wlvL0vQcIGeH",
    "outputId": "9c6782d3-d3f2-4d85-d07e-d68eef133daa"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/muhammadusman/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "import math\n",
    "import re\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "id": "uMPyn6QPYDdy",
    "outputId": "d21ecc99-42e8-4619-c650-ddc85a56f234"
   },
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"task1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "7r6bfrjmIHwU"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['review'].values, data['sentiment'].values, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Ifov_XqaCBxI"
   },
   "outputs": [],
   "source": [
    "class Preprocessing:\n",
    "  \n",
    "  def clean(self, text):\n",
    "      no_html = BeautifulSoup(text).get_text()\n",
    "      for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "      return text\n",
    "\n",
    " \n",
    "  def tokenize(self, text):\n",
    "      clean = self.clean(text).lower()\n",
    "      stopwords_en = stopwords.words(\"english\")\n",
    "      return [w for w in re.split(\"\\W+\", clean) if not w in stopwords_en]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JnOAO_Kl4BkQ"
   },
   "outputs": [],
   "source": [
    "class MultinomialNaiveBayes:\n",
    "  \n",
    "    def __init__(self, classes, processes_text):\n",
    "      self.processes_text = processes_text\n",
    "      self.classes = classes\n",
    "      print(self.classes)\n",
    "    \n",
    "      \n",
    "    def group_by_class(self, X, y):\n",
    "      data = dict()\n",
    "      for c in self.classes:\n",
    "        data[c] = X[np.where(y == c)]\n",
    "      return data\n",
    "           \n",
    "    def fit(self, X, y):\n",
    "        self.n_class_items = {}\n",
    "        self.log_class_priors = {}\n",
    "        self.word_counts = {}\n",
    "        self.vocab = set()\n",
    "\n",
    "        n = len(X)\n",
    "        \n",
    "        grouped_data = self.group_by_class(X, y)\n",
    "        \n",
    "        for c, data in grouped_data.items():\n",
    "          self.n_class_items[c] = len(data)\n",
    "          self.log_class_priors[c] = math.log(self.n_class_items[c] / n)\n",
    "          self.word_counts[c] = defaultdict(lambda: 0)\n",
    "          \n",
    "          for text in data:\n",
    "            counts = Counter(self.processes_text.tokenize(text))\n",
    "            for word, count in counts.items():\n",
    "                if word not in self.vocab:\n",
    "                    self.vocab.add(word)\n",
    "\n",
    "                self.word_counts[c][word] += count\n",
    "                \n",
    "        return self\n",
    "      \n",
    "    def laplace_smoothing(self, word, text_class):\n",
    "      num = self.word_counts[text_class][word] + 1\n",
    "      denom = self.n_class_items[text_class] + len(self.vocab)\n",
    "      return math.log(num / denom)\n",
    "      \n",
    "    def predict(self, X):\n",
    "        result = []\n",
    "        for text in X:\n",
    "          \n",
    "          class_scores = {c: self.log_class_priors[c] for c in self.classes}\n",
    "\n",
    "          words = set(self.processes_text.tokenize(text))\n",
    "          for word in words:\n",
    "              if word not in self.vocab: continue\n",
    "\n",
    "              for c in self.classes:\n",
    "                \n",
    "                log_w_given_c = self.laplace_smoothing(word, c)\n",
    "                class_scores[c] += log_w_given_c\n",
    "                \n",
    "          result.append(max(class_scores, key=class_scores.get))\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "ruhWLRfz4SlE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['negative' 'positive']\n"
     ]
    }
   ],
   "source": [
    "MNB = MultinomialNaiveBayes(\n",
    "    classes=np.unique(data['sentiment'].values), \n",
    "    processes_text=Preprocessing()\n",
    ").fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5-aAAa3O5gKs"
   },
   "outputs": [],
   "source": [
    "y_hat = MNB.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "dfFrVVFP-sUn",
    "outputId": "7bb318e6-bc15-411b-8946-af0f0eaf8446"
   },
   "outputs": [],
   "source": [
    "accuracy_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "id": "83tQ3ERwRTgP",
    "outputId": "b1cd6b41-7bc4-45e6-ccd4-2acfa974ca76"
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_hat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "djMXLvXdRVKd",
    "outputId": "c3d5d583-4347-4feb-8ca2-c5e5acc1e479"
   },
   "outputs": [],
   "source": [
    "cnf_matrix = confusion_matrix(y_test, y_hat)\n",
    "cnf_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 580
    },
    "id": "tkEbxgwORgOW",
    "outputId": "90200f02-a429-49a4-a86e-195f59b56a88"
   },
   "outputs": [],
   "source": [
    "class_names = [\"Negative\", \"Positive\"]\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "\n",
    "sns.heatmap(pd.DataFrame(cnf_matrix), annot=True, cmap=\"Blues\", fmt=\"d\", cbar=False, xticklabels=class_names, yticklabels=class_names)\n",
    "ax.xaxis.set_label_position('top')\n",
    "plt.tight_layout()\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jQYDzvBJRoHP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of 5.sentiment_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
