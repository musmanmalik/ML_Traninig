{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "import nltk\n",
    "\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading to Dataframe & Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"task1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review       0\n",
       "sentiment    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Encoding Categorical Data\n",
    "data['sentiment'] = data['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "data['sentiment'] = data['sentiment'].astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['review_clean'] = data['review'].str.replace(r'<[^<>]*>', '', regex=True)\n",
    "data['review_clean'] = data['review_clean'].str.replace(r'[?|!|\\'|\"|#]', '', regex=True)\n",
    "data['review_clean'] = data['review_clean'].str.replace(r'[.|,|)|(|\\|/]', ' ', regex=True)\n",
    "\n",
    "stopwords = set(stopwords.words('english')) \n",
    "stemmer = nltk.stem.SnowballStemmer('english') \n",
    "index=0\n",
    "str=' '\n",
    "final_string=[]\n",
    "s=''\n",
    "for sent in data['review_clean'].values:\n",
    "    filtered_sentence=[]\n",
    "    for word in sent.split():\n",
    "        if((word.isalpha()) & (len(word)>2)):    \n",
    "            if(word.lower() not in stopwords):\n",
    "                s=(stemmer.stem(word.lower()))\n",
    "                #print(s)\n",
    "                filtered_sentence.append(s)\n",
    "            else:\n",
    "                continue\n",
    "        else:\n",
    "            continue     \n",
    "    str = \" \".join(filtered_sentence)     \n",
    "    final_string.append(str)\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['cleaned_review']=final_string\n",
    "data['cleaned_review'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtrain, xtest, ytrain, ytest = train_test_split(data['cleaned_review'], data['sentiment'], test_size = 0.3, random_state = 42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF_IDF\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "tf_idf_train = tf_idf_vect.fit_transform(xtrain.values)\n",
    "tf_idf_test = tf_idf_vect.transform(xtest.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Finding the optimal value of parameter alpha\n",
    "alpha_range = list(np.arange(1,20,2))\n",
    "alpha_scores=[]\n",
    "\n",
    "for a in alpha_range:\n",
    "    clf = MultinomialNB(alpha=a)\n",
    "    scores = cross_val_score(clf, tf_idf_train, ytrain, cv=6, scoring='accuracy')\n",
    "    alpha_scores.append(scores.mean())\n",
    "MSE = [1 - x for x in alpha_scores]\n",
    "\n",
    "optimal_alpha = alpha_range[MSE.index(min(MSE))]\n",
    "plt.plot(alpha_range, MSE)\n",
    "\n",
    "plt.xlabel('Alpha')\n",
    "plt.ylabel('Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model Using Multinomial NBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = MultinomialNB(alpha=optimal_alpha)\n",
    "clf.fit(tf_idf_train,ytrain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = clf.predict(tf_idf_train)\n",
    "acc_training = accuracy_score(ytrain, y_pred_train, normalize=True)\n",
    "print('Training accuracy is: ', (acc_training))\n",
    "\n",
    "cm_training = confusion_matrix(ytrain,y_pred_train)\n",
    "tn_training = cm_training[0][0]\n",
    "fn_training = cm_training[0][1]\n",
    "fp_training = cm_training[1][0]\n",
    "tp_training = cm_training[1][1]\n",
    "actual_negative_training=tn_training+fp_training\n",
    "actual_positive_training=fn_training+tp_training\n",
    "\n",
    "precision_training=tp_training/(tp_training+fp_training)\n",
    "print(\"Precision on Training\",precision_training)\n",
    "recall_training = tp_training/actual_positive_training\n",
    "print(\"Recall on Training\",recall_training)\n",
    "f1_training = 2*((precision_training*recall_training)/(precision_training+recall_training))\n",
    "print(\"f1-score on training\",f1_training)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation on Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = clf.predict(tf_idf_test)\n",
    "acc = accuracy_score(ytest, y_pred_test, normalize=True)#If False, return the number of correctly classified samples. Otherwise, return the fraction of correctly classified samples.\n",
    "print('Test accuracy is: ',(acc))\n",
    "\n",
    "cm_test = confusion_matrix(ytest,y_pred_test)\n",
    "sns.heatmap(cm_test,annot=True,fmt='d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "precision, recall, fscore, support = score(ytest, y_pred_test)\n",
    "\n",
    "print('precision: {}'.format(precision))\n",
    "print('recall: {}'.format(recall))\n",
    "print('fscore: {}'.format(fscore))\n",
    "print('support: {}'.format(support))#number of occurrences of each class in y_true\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Source: https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
